{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "refs:\n",
    "* https://blog.goodaudience.com/artificial-neural-networks-explained-436fcf36e75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main concepts \n",
    "\n",
    "\n",
    "ANN can learning non-linear relationships \n",
    "\n",
    "<img src=\"images/non-linear_and_linear_decision_edge.png\" width=\"400\" align=\"left\"/> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "* neuron\n",
    "\n",
    "<div style=\"clear:both\">\n",
    "<img src=\"images/neuron_ANN.png\" width=\"400\" align=\"left\"/> \n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"clear:both\">\n",
    "** activation func (**allow ANN to learn no-linear relationships**) \n",
    "\n",
    "    Good activatiobn functions has non-linear shapes, easy to compute the function and the first derivative of the function\n",
    "\n",
    "*** **sigmoid function**: most common function. widely used on logiostic regression  \n",
    "**** (range: 0.0 and 1.0)  \n",
    "**** good for binnary classifiers (output layer) \n",
    "\n",
    "\n",
    "*** **softmax**: \n",
    "**** range: vector where each element is between 0.0 and 1.0. There is nclass elements in the vector output\n",
    "**** good for multi-class classificatio (output layer)\n",
    "**** emphsaize the most likely class and return probabilities\n",
    "\n",
    "*** **tanh**: hyperbolic tangent   \n",
    "**** range: -1.0 and 1.0  \n",
    "**** mean value is zero this is good in optimization problems (remember why we should normalize the input features)  \n",
    "**** good for hidden layers  \n",
    "\n",
    "*** **ReLu**: very common  \n",
    "*** range: 0  and inf   \n",
    "*** good for hidden layers  \n",
    "</div>\n",
    "\n",
    "* layers  \n",
    "\n",
    "<div style=\"clear:both\">\n",
    "<img src=\"images/layers.jpeg\" width=\"400\" align=\"left\"/> \n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"clear:both\">\n",
    "* Loss\n",
    "\n",
    "*** **cross-entropy loss** or **or log loss**: measure the performance of classifier where the outputs ranging between 0.0 and 1.0 \n",
    "\n",
    "Cross-entropy loss increases as the predicted probability diverges from the actual label\n",
    "Is the average of log likelihood over all the data\n",
    "\n",
    "* Forward Propagation: computes the output given an input. (used in train and prediction phase)\n",
    "\n",
    "* Back-propagation: computes the gradiens in order to train the model while the ANN is learning. Only used in train phase\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train recipe\n",
    "\n",
    "refs: http://karpathy.github.io/2019/04/25/recipe/\n",
    "\n",
    "1. General advices\n",
    "\n",
    "    * fast n furious approach does not work\n",
    "    * patient and pay attention in detail tends to work (correlates with success)\n",
    "    * being defensive and obsessed about visualizations works\n",
    "    * do baby steps and avoid to **introduce a lot of unverified complexity at once**\n",
    "    * Build simple to complex\n",
    "    * ReLu are good for hidden layers\n",
    "        * Positive side learn faster than logistic and tanh due to the slope\n",
    "        * The Negative side can make train stuck caused by dead neurons where the gradient becomes zero\n",
    "    \n",
    "1. Become one with data \n",
    "\n",
    "    * inspect data\n",
    "    * try to see patterns (your brain is good at it)\n",
    "    * always check for:\n",
    "        * duplicated \n",
    "        * corrupted data\n",
    "        * wrong labels (if not systemic may not hurt to much)\n",
    "        * imbalance data\n",
    "        \n",
    "1. Set up pipeline for trainning and evaluations and test it\n",
    "\n",
    "    * work with fixed seed\n",
    "    * simplify . does not add any regularization\n",
    "    * **verify loss init**: -log(1/n_classes) for classifiers\n",
    "    * **overfit one batch or small train sample dataset as little as 2**\n",
    "    * **input independent** (shuffles labels) (the DNN should not learn. See the errors in test n val dataset)\n",
    "    * visualize the input of DNN. y_hat = model(X). Vis X.  \n",
    "\n",
    "1. Overfit (reduce bias error)\n",
    "\n",
    "    * overfit\n",
    "        * focus in **train loss** should be close to zero\n",
    "        * if you try with many models  that you increased the complexity can suggest that you have a BUG\n",
    "    * do not be a hero. start with the most related paper and copy and paste their simple architecture.\n",
    "        * for images, ResNet-50 is a good start\n",
    "        * for voice, xvectors\n",
    "    * **Adam is safe with learning rate e3-4** !? but you can try different learning rate.\n",
    "    * **Add complexity only one at time**. If you have multiple features. Suggest to add one by one and unsure you get a performance boost. Or you can try smaller image and the increase the image size \n",
    "    * **do not trust learning rate decay**. He always disable learning rate decays entirely. It is a personal advice. less problematic maybe\n",
    "\n",
    "1. Regularize (reduce variance error)\n",
    "\n",
    "    * **get more data** is by the far preferred way to regularize a model. It is **the only guarantee way to improve the model.**\n",
    "    * **data augmentation**. The next best thing\n",
    "    * **pretrain**. It is really rarely hurts to use a pre-trained network even if you have enough data.\n",
    "        * xvectors\n",
    "        * ResNet-50\n",
    "    * **make smaller input dimensionality**. Remove features that can have spurious signal (Remove ciorrelated features)\n",
    "    * **make smaller model**. Personal advise\n",
    "        * He used to use FC layers after ImageNet, but these days he uses average pooling. eliminating a tons of parameters\n",
    "    * **decrease batch size**. helps with regularization\n",
    "    * **dropout**\n",
    "    * **early stopping**\n",
    "    \n",
    "1. Tune\n",
    "\n",
    "    * **random over grid search** Never use grid serach\n",
    "    * **hyper-parameter optmization**\n",
    "    \n",
    "    \n",
    "1. Squeeze the juice (It is not preference)\n",
    "\n",
    "    * leave it training. One time he forgot one model running and get SOTA (state of the art) !?\n",
    "    * ensembles\n",
    "        * TODO: read this paper about hot to use ensemble to build one simple model: https://arxiv.org/abs/1503.02531\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate diagnostics \n",
    "\n",
    "* refs:\n",
    "    \n",
    "    * https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10   (approach to detrmine best lr)\n",
    "    * https://www.dataquest.io/blog/learning-curves-machine-learning/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/sdb1/leandro/ds_pragmatic_programming\n",
      "data_frame.png\t\t\t\t pathlib_cheatsheet_p1.png\n",
      "iris_petal_sepal.png\t\t\t pivot-table-datasheet.png\n",
      "layers.jpeg\t\t\t\t refactor_notebooks.png\n",
      "neuron_ANN.png\t\t\t\t resampling.png\n",
      "non-linear_and_linear_decision_edge.png  smote.png\n",
      "notebook_vs_code.png\t\t\t split-apply-combine.png\n",
      "onehot.png\t\t\t\t tomek.png\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias and variance trade-off \n",
    "\n",
    "**Train error still to much high for the application**\n",
    "\n",
    "<img src=\"images/biasvariance.png\" height=\"250\" width=\"400\">\n",
    "\n",
    "**variance error is related to gap between train and error** \n",
    "\n",
    "There is a minimum total error\n",
    "\n",
    "<img src=\"images/irr_error.png\" height=\"250\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High bias\n",
    "\n",
    "\n",
    "* left: high bias and low variance \n",
    "* right: high bias and high variance\n",
    "\n",
    "What to do:\n",
    "\n",
    "* Adding more training instances.\n",
    "* Adding more features.\n",
    "* Feature selection.\n",
    "* Hyperparameter optimization\n",
    "* train longer (deep learning)\n",
    "\n",
    "<img src=\"images/add_data.png\" height=\"400\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low bias high variance error\n",
    "\n",
    "\n",
    "* left: low variance \n",
    "* right: high variance\n",
    "\n",
    "What to do?\n",
    "\n",
    "* Adding more training instances.  \n",
    "\n",
    "* Increase the regularization for our current learning algorithm. This should decrease the variance and increase the bias.  \n",
    "\n",
    "    * L1 or L2\n",
    "    * dropout\n",
    "\n",
    "* Reducing the numbers of features in the training data we currently use. The algorithm will still fit the training data very well, but due to the decreased number of features, it will build less complex models. This should increase the bias and decrease the variance. \n",
    "\n",
    "\n",
    "<img src=\"images/low_high_var.png\" height=\"400\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rates \n",
    "\n",
    "Learning rate controls how much we are adjusting the weights of our network with respect the gradient of the loss function. \n",
    "\n",
    "\n",
    "<img src=\"images/learning_rate.png\" height=\"400\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Too small: **Less training time, lesser money spent on GPU cloud compute. :)**\n",
    "* Too large: does not converge\n",
    "\n",
    "<img src=\"images/learning_rate2.png\" height=\"200\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a methodology to detrmine best learning rate?\n",
    "\n",
    "In the article **Cyclical Learning Rates for Training Neural Networks\"\"** Leslie N. Smith argued that you could estimate a good learning rate by training the model initially with a very low learning rate and increasing it (either linearly or exponentially) at each iteration.\n",
    "\n",
    "\n",
    "1. change the learningrate at each minibatch (lienarlly or exponentially)\n",
    "1. plot the learning rate (log) against loss; (choose the one close to the minumum)\n",
    "\n",
    "\n",
    "**The python package fastai has function to do that** fastai is like keras for pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips n learning curve diagnostics\n",
    "\n",
    "* https://stats.stackexchange.com/questions/345990/why-does-the-loss-accuracy-fluctuate-during-the-training-keras-lstm\n",
    "\n",
    "* https://stats.stackexchange.com/questions/187335/validation-error-less-than-training-error \n",
    "\n",
    "**Summary**\n",
    "\n",
    "* val loss or error smaller than train reasons\n",
    "    * diff in train and val data distributions. \n",
    "        * Maybe train has harder case while validation has more easy cases.\n",
    "        * data wrongly labeledin train datasets\n",
    "        * dropouts (highe level) can cause that sometimes\n",
    "\n",
    "* loss oscilation reasons\n",
    "    1. batch_size is too small\n",
    "    1. large neural network and small data  (**always compare #parmeters and #samples**)\n",
    "    \n",
    "    \n",
    "* Batch size trade off (alsoe related to previous one)\n",
    "    * too large make training slow\n",
    "    * too small loss oscilation and takes more epoch to converge\n",
    "    * large batch (**small number of mini batches** per epoch) size can make the DNN not learn\n",
    "\n",
    "You can think of model evaluation in four different categories:\n",
    "\n",
    "1. Underfitting – Validation and training error high\n",
    "\n",
    "1. Overfitting – Validation error is high, training error low\n",
    "\n",
    "1. Good fit – Validation error low, slightly higher than the training error\n",
    "\n",
    "1. Unknown fit - Validation error low, training error 'high'\n",
    "\n",
    "\n",
    "I say 'unknown' fit because the result is counter intuitive to how machine learning works. The essence of ML is to predict the unknown. If you are better at predicting the unknown than what you have 'learned', AFAIK the data between training and validation must be different in some way. \n",
    "\n",
    "\n",
    "=================================\n",
    "\n",
    "There are several reasons that can cause fluctuations in training loss over epochs. The main one though is the fact that almost all neural nets are trained with different forms of stochastic gradient decent. This is why batch_size parameter exists which determines how many samples you want to use to make one update to the model parameters. If you use all the samples for each update, you should see it decreasing and finally reaching a limit. Note that there are other reasons for the loss having some stochastic behavior.\n",
    "\n",
    "This explains why we see oscillations. But in your case, it is more that normal I would say. Looking at your code, I see two possible sources.\n",
    "\n",
    "Large network, small dataset: It seems you are training a relatively large network with 200K+ parameters with a very small number of samples, ~100. To put this into perspective, you want to learn 200K parameters or find a good local minimum in a 200K-D space using only 100 samples. Thus, you might end up just wandering around rather than locking down on a good local minima. (The wandering is also due to the second reason below).\n",
    "\n",
    "Very small batch_size. You use very small batch_size. So it's like you are trusting every small portion of the data points. Let's say within your data points, you have a mislabeled sample. This sample when combined with 2-3 even properly labeled samples, can result in an update which does not decrease the global loss, but increase it, or throw it away from a local minima. When the batch_size is larger, such effects would be reduced. Along with other reasons, it's good to have batch_size higher than some minimum. Having it too large would also make training go slow. Therefore, batch_size is treated as a hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent algorithms\n",
    "\n",
    "refs: https://stats.stackexchange.com/questions/49528/batch-gradient-descent-versus-stochastic-gradient-descent\n",
    "\n",
    "$\n",
    "J(\\theta)=\\frac{1}{2}\\sum_{i=1}^N(y_i−h_{\\theta}(x_i)^2\n",
    "$\n",
    "\n",
    "$\n",
    "\\theta_j = \\theta_j − \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} \n",
    "$\n",
    "\n",
    "The update is given by \n",
    "\n",
    "\n",
    "$\n",
    "\\Delta \\theta_j = \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} \\equiv  \\sum_{i=1}^N(y_i−h_{\\theta}(x_i))x_i\n",
    "$\n",
    "\n",
    "1. Gradient descent  \n",
    "\n",
    "    1. Compute the gradient of the cost function using the entire dataset \n",
    "    \n",
    "    1. Update the weights.\n",
    "    \n",
    "    Pros n cons  \n",
    "    \n",
    "    * **Computational slow and utilizes a lot of memory**  \n",
    "    * Guarantee that loss func always will reduce  \n",
    "    \n",
    "\n",
    "1. Stochastic Gradient Descent\n",
    "    1. Compute gradient for each sample\n",
    "    \n",
    "    pros n cons  \n",
    "    \n",
    "    * More sensible to noisy  \n",
    "    * Faster than Gradient decsent  \n",
    "    * Use less memmory   \n",
    "\n",
    "\n",
    "1. Mini batch Gradient  \n",
    "\n",
    "    1. Compute gradient for each mini batch (This is a estimation of the true Gradient )  \n",
    "\n",
    "    Pros n Cons  \n",
    "    \n",
    "    * More robust to noisys data\n",
    "    * Faster than all methods\n",
    "    * Use less memory than Gradient but more than Stochastic\n",
    "    \n",
    "\n",
    "See this discusison for batches sizes:\n",
    "* https://stats.stackexchange.com/questions/316464/how-does-batch-size-affect-convergence-of-sgd-and-why\n",
    "\n",
    ">  the minibatch size gets larger the convergence of SGD actually gets harder/worse,\n",
    "\n",
    "* Paper: https://research.fb.com/publications/accurate-large-minibatch-sgd-training-imagenet-in-1-hour/\n",
    "\n",
    ">  large minibatches cause optimization difficulties, but when these are addressed the trained networks exhibit good generalization.  \n",
    "\n",
    "* https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network/236393#236393 \n",
    "\n",
    "> It has been observed in practice that when using a larger batch there is a significant degradation in the quality of the model, as measured by its ability to generalize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow \n",
    "\n",
    "**TODO** Change for 2.0\n",
    "\n",
    "refs:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/estimators/cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html\n",
    "\n",
    "```sh\n",
    "conda create -n tensorflow_cpu pip python=3.6\n",
    "\n",
    "source activate tensorflow_cpu\n",
    "\n",
    "# install tensorflow \n",
    "pip install --ignore-installed --upgrade tensorflow==1.9\n",
    "\n",
    "# test instalations\n",
    "python -c \"import tensorflow as tf; print(tf.__version__)\"\n",
    "\n",
    "# Save enviroment for later use\n",
    "conda env export > tensorflow_cpu.yml\n",
    "conda list -e > requirements.txt\n",
    "\n",
    "# actvate the enviroment in jupyter notebook\n",
    "# RUN outisde the env tensorflow\n",
    "# In caseyou want to use the same terminal you need to run deactivate\n",
    "deactivate\n",
    "\n",
    "# install ipykernel\n",
    "conda install -c anaconda ipykernel \n",
    "\n",
    "# install env in jupyter notebook. NOW youcan select this env n change kernel tab\n",
    "python -m ipykernel install --user --name tensorflow_cpu --display-name \"Python (tensorflow)\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:21:22.344578Z",
     "start_time": "2019-05-16T01:21:11.912985Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leandroohf/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics \n",
    "\n",
    "* define variables, const n placeholders\n",
    "\n",
    "**remember to initialize your variables, create a session and run the operations inside the session**. \n",
    "\n",
    "A placeholder is an object whose value you can specify only later. \n",
    "To specify values for a placeholder, you can pass in values by using a \"feed dictionary\" (`feed_dict` variable). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:21:22.399111Z",
     "start_time": "2019-05-16T01:21:22.346368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "6\n",
      "\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "[[ 1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12]]\n",
      "\n",
      "(2, 2, 3)\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.constant(36, name='y_hat')            # Define y_hat constant. Set to 36.\n",
    "y = tf.constant(39, name='y')                    # Define y. Set to 39\n",
    "\n",
    "loss = tf.Variable((y - y_hat)**2, name='loss')  # Create a variable for the loss\n",
    "\n",
    "init = tf.global_variables_initializer()         # When init is run later (session.run(init)),\n",
    "                                                 # the loss variable will be initialized and ready to be computed\n",
    "with tf.Session() as session:                    # Create a session and print the output\n",
    "    session.run(init)                            # Initializes the variables\n",
    "    print(session.run(loss))                     # Prints the loss\n",
    "    \n",
    "    \n",
    "# Change the value of x in the feed_dict\n",
    "# See the function one hot encoding below\n",
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "\n",
    "\n",
    "print()\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    x = tf.reshape(np.array([1,2,3,4,5,6,7,8,9]), [3, 3])    \n",
    "    print(sess.run(x))\n",
    "    \n",
    "    print()\n",
    "    # -1 means infere this dimension\n",
    "    y = tf.reshape(np.array([1,2,3,4,5,6,7,8,9,10,11,12]), [2, -1])\n",
    "    print(sess.run(y))\n",
    "    \n",
    "    print()\n",
    "    z = tf.reshape(np.array([1,2,3,4,5,6,7,8,9,10,11,12]), [-1, 2, 3])\n",
    "    \n",
    "    zl = sess.run(z)\n",
    "\n",
    "    print(np.shape(zl))\n",
    "    print(zl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:16:21.750111Z",
     "start_time": "2019-05-14T23:16:21.746973Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Encoding\n",
    "\n",
    "* One hot encoding\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/one_hot\n",
    "\n",
    "```txt\n",
    "tf.one_hot(\n",
    "    indices,\n",
    "    depth,\n",
    "    on_value=None,\n",
    "    off_value=None,\n",
    "    axis=None,\n",
    "    dtype=None,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "Returns a one-hot tensor.\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"images/onehot.png\" width=\"800\" align=\"left\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:24:46.010298Z",
     "start_time": "2019-05-14T23:24:45.972069Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name='C')\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(indices=labels, depth=C, axis=0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "labels = np.array([1,2,3])\n",
    "\n",
    "one_hot = one_hot_matrix(labels, C=3)\n",
    "print (\"one_hot = \\n\" + str(one_hot))\n",
    "\n",
    "# I do not know when this case is important. BUt heklps understand depth\n",
    "one_hot = one_hot_matrix(labels, C=4)\n",
    "print (\"one_hot = \\n\" + str(one_hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train \n",
    "\n",
    "\n",
    "- **Training set**: 1080 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (180 pictures per number).\n",
    "- **Test set**: 120 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (20 pictures per number).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:20:05.450391Z",
     "start_time": "2019-05-15T22:20:05.405403Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \n",
    "    train_dataset = h5py.File('data/train_signs.h5', \"r\")\n",
    "    \n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('data/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:20:06.228960Z",
     "start_time": "2019-05-15T22:20:06.076697Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.shape(classes))\n",
    "print(classes)\n",
    "\n",
    "# See example of image\n",
    "index = 0\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* preprocessing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:48:24.233605Z",
     "start_time": "2019-05-14T23:48:24.164274Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "# Flatten the training and test images\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_flatten / 255.\n",
    "X_test = X_test_flatten / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[1]))\n",
    "\n",
    "print()\n",
    "print('64*64*3 = 12288')\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n",
    "print()\n",
    "print (\"Y_test (1st 5) = \\n\" + str(np.squeeze(Y_test[:,0:5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# Use the loss function (approx. 1 line)\n",
    "cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z, labels=y)\n",
    "\n",
    "```\n",
    "\n",
    "$$- \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log \\sigma(z^{[2](i)}) + (1-y^{(i)})\\log (1-\\sigma(z^{[2](i)})\\large )\\small\\tag{2}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_network():\n",
    "    \n",
    "    with tf.variable_scope('mymodel'):\n",
    "        \n",
    "    # Add a fully connected layer with 100 units.\n",
    "    num_units = 100\n",
    "    fc = slim.fully_connected(embeddings, num_units)\n",
    "\n",
    "    # Add a classifier layer at the end, consisting of parallel logistic\n",
    "    # classifiers, one per class. This allows for multi-class tasks.\n",
    "    logits = slim.fully_connected( fc, _NUM_CLASSES, activation_fn=None, scope='logits')\n",
    "        \n",
    "    tf.sigmoid(logits, name='prediction')\n",
    "\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction or inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow slim\n",
    "\n",
    "**TF-Slim: A high level library to define complex models in TensorFlow**\n",
    "\n",
    "refs:\n",
    "\n",
    "https://cv-tricks.com/tensorflow-tutorial/understanding-alexnet-resnet-squeezenetand-running-on-tensorflow/\n",
    "\n",
    "https://github.com/tensorflow/models/blob/master/research/slim/slim_walkthrough.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Comparing slim with tensorflow. You need less lines of code to do the same**. But tensorflow gives you more flexibility and it is easy to see the learning curves\n",
    "\n",
    "```python\n",
    "# using slim\n",
    "net = slim.conv2d(input, 128,[3, 3], scope='conv1_1')\n",
    "\n",
    "# slim version\n",
    "with tf.name_scope('conv1_1') as scope:\n",
    "    \n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3,  64,128], dtype=tf.float32,stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(input, kernel,[1, 1, 1, 1], padding='SAME')\n",
    " \n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32), trainable=True, name='biases')\n",
    "    \n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    " \n",
    "    conv1 = tf.nn.relu(bias, name=scope)\n",
    "     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:21:23.284775Z",
     "start_time": "2019-05-16T01:21:23.195692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers\n",
      "name = deep_regression/fc1/Relu:0, shape = (?, 32)\n",
      "name = deep_regression/fc2/Relu:0, shape = (?, 16)\n",
      "name = deep_regression/prediction/BiasAdd:0, shape = (?, 1)\n",
      "\n",
      "\n",
      "Parameters\n",
      "name = deep_regression/fc1/weights:0, shape = (1, 32)\n",
      "name = deep_regression/fc1/biases:0, shape = (32,)\n",
      "name = deep_regression/fc2/weights:0, shape = (32, 16)\n",
      "name = deep_regression/fc2/biases:0, shape = (16,)\n",
      "name = deep_regression/prediction/weights:0, shape = (16, 1)\n",
      "name = deep_regression/prediction/biases:0, shape = (1,)\n"
     ]
    }
   ],
   "source": [
    "def regression_model(inputs, is_training=True, scope=\"deep_regression\"):\n",
    "    \"\"\"Creates the regression model.\n",
    "\n",
    "    Args:\n",
    "        inputs: A node that yields a `Tensor` of size [batch_size, dimensions].\n",
    "        is_training: Whether or not we're currently training the model.\n",
    "        scope: An optional variable_op scope for the model.\n",
    "\n",
    "    Returns:\n",
    "        predictions: 1-D `Tensor` of shape [batch_size] of responses.\n",
    "        end_points: A dict of end points representing the hidden layers.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope, 'deep_regression', [inputs]):\n",
    "        \n",
    "        end_points = {}\n",
    "        \n",
    "        # Set the default weight _regularizer and acvitation for each fully_connected layer.\n",
    "        # To set defaults parameters for a layer type\n",
    "        with slim.arg_scope([slim.fully_connected],\n",
    "                            activation_fn=tf.nn.relu,\n",
    "                            weights_regularizer=slim.l2_regularizer(0.01)):\n",
    "\n",
    "            # Creates a fully connected layer from the inputs with 32 hidden units.\n",
    "            net = slim.fully_connected(inputs, 32, scope='fc1')\n",
    "            end_points['fc1'] = net\n",
    "\n",
    "            # Adds a dropout layer to prevent over-fitting.\n",
    "            net = slim.dropout(net, 0.8, is_training=is_training)\n",
    "\n",
    "            # Adds another fully connected layer with 16 hidden units.\n",
    "            net = slim.fully_connected(net, 16, scope='fc2')\n",
    "            end_points['fc2'] = net\n",
    "\n",
    "            # Creates a fully-connected layer with a single hidden unit. Note that the\n",
    "            # layer is made linear by setting activation_fn=None.\n",
    "            predictions = slim.fully_connected(net, 1, activation_fn=None, scope='prediction')\n",
    "            end_points['out'] = predictions\n",
    "\n",
    "            return predictions, end_points\n",
    "\n",
    "        \n",
    "# Underatnd the model\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    # Dummy placeholders for arbitrary number of 1d inputs and outputs\n",
    "    inputs = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    #outputs = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "    # Build model\n",
    "    predictions, end_points = regression_model(inputs)\n",
    "\n",
    "    # Print name and shape of each tensor.\n",
    "    print(\"Layers\")\n",
    "    for k, v in end_points.items():\n",
    "        print('name = {}, shape = {}'.format(v.name, v.get_shape()))\n",
    "\n",
    "    # Print name and shape of parameter nodes  (values not yet initialized)\n",
    "    print(\"\\n\")\n",
    "    print(\"Parameters\")\n",
    "    for v in slim.get_model_variables():\n",
    "        print('name = {}, shape = {}'.format(v.name, v.get_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using slim.learning.train\n",
    "\n",
    "**Use slim training procedure is hard to get the learning curves and evaluations**. Its being criticized by the comunity. Might be why Google use slim to build the mode and for loop to train the model instead.\n",
    "\n",
    "```python\n",
    " final_loss = slim.learning.train(\n",
    "        train_op,\n",
    "        logdir=ckpt_dir,\n",
    "        number_of_steps=5000,\n",
    "        graph=graph,\n",
    "        save_summaries_secs=5,\n",
    "        log_every_n_steps=500)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:21:33.664955Z",
     "start_time": "2019-05-16T01:21:33.498995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f40540c32b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create fake data to test the mode\n",
    "\n",
    "def produce_batch(batch_size, noise=0.3):\n",
    "    xs = np.random.random(size=[batch_size, 1]) * 10\n",
    "    ys = np.sin(xs) + 5 + np.random.normal(size=[batch_size, 1], scale=noise)\n",
    "    return [xs.astype(np.float32), ys.astype(np.float32)]\n",
    "\n",
    "# needs to run under with tf.Graph().as_default():\n",
    "def convert_data_to_tensors(x, y):\n",
    "    inputs = tf.constant(x)\n",
    "    inputs.set_shape([None, 1])\n",
    "    \n",
    "    outputs = tf.constant(y)\n",
    "    outputs.set_shape([None, 1])\n",
    "    return inputs, outputs\n",
    "\n",
    "x_train, y_train = produce_batch(200)\n",
    "x_test, y_test = produce_batch(200)\n",
    "plt.scatter(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can run and the checkpoints will be save and I can change the learn rate and run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:29:27.270861Z",
     "start_time": "2019-05-16T01:29:27.145069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'tmp/regression_model/checkpoint'\r\n",
      "removed 'tmp/regression_model/events.out.tfevents.1557950295.leandroohf-VirtualBox'\r\n",
      "removed 'tmp/regression_model/events.out.tfevents.1557950303.leandroohf-VirtualBox'\r\n",
      "removed 'tmp/regression_model/events.out.tfevents.1557950313.leandroohf-VirtualBox'\r\n",
      "removed 'tmp/regression_model/graph.pbtxt'\r\n",
      "removed 'tmp/regression_model/model.ckpt-0.data-00000-of-00001'\r\n",
      "removed 'tmp/regression_model/model.ckpt-0.index'\r\n",
      "removed 'tmp/regression_model/model.ckpt-0.meta'\r\n",
      "removed 'tmp/regression_model/model.ckpt-10000.data-00000-of-00001'\r\n",
      "removed 'tmp/regression_model/model.ckpt-10000.index'\r\n",
      "removed 'tmp/regression_model/model.ckpt-10000.meta'\r\n",
      "removed 'tmp/regression_model/model.ckpt-5000.data-00000-of-00001'\r\n",
      "removed 'tmp/regression_model/model.ckpt-5000.index'\r\n",
      "removed 'tmp/regression_model/model.ckpt-5000.meta'\r\n",
      "removed 'tmp/regression_model/model.ckpt.data-00000-of-00001'\r\n",
      "removed 'tmp/regression_model/model.ckpt.index'\r\n",
      "removed 'tmp/regression_model/model.ckpt.meta'\r\n"
     ]
    }
   ],
   "source": [
    "# clean up checkppoints\n",
    "!rm -vf tmp/regression_model/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:29:35.349598Z",
     "start_time": "2019-05-16T01:29:28.888727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py:737: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path tmp/regression_model/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global step 500: loss = 0.3755 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 1000: loss = 0.2620 (0.001 sec/step)\n",
      "INFO:tensorflow:global step 1500: loss = 0.2592 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 2000: loss = 0.2003 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 2500: loss = 0.1961 (0.001 sec/step)\n",
      "INFO:tensorflow:global step 3000: loss = 0.2028 (0.001 sec/step)\n",
      "INFO:tensorflow:global step 3500: loss = 0.2044 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 4000: loss = 0.2109 (0.001 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 898.075\n",
      "INFO:tensorflow:global step 4500: loss = 0.1922 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 5000: loss = 0.1854 (0.001 sec/step)\n",
      "INFO:tensorflow:Stopping Training.\n",
      "INFO:tensorflow:Finished training! Saving model to disk.\n",
      "Finished training. Last batch loss: 0.18536729\n",
      "Checkpoint saved in tmp/regression_model/\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "ckpt_dir = 'tmp/regression_model/'\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    inputs, targets = convert_data_to_tensors(x_train, y_train)\n",
    "\n",
    "    # Make the model.\n",
    "    predictions, nodes = regression_model(inputs, is_training=True)\n",
    "\n",
    "    # Add the loss function to the graph.\n",
    "    loss = tf.losses.mean_squared_error(labels=targets, predictions=predictions)\n",
    "    \n",
    "    # The total loss is the user's loss plus any regularization losses.\n",
    "    total_loss =  tf.losses.get_total_loss()# slim.losses.get_total_loss()\n",
    "\n",
    "    # Specify the optimizer and create the train op:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0075)\n",
    "    train_op = slim.learning.create_train_op(total_loss, optimizer) \n",
    "\n",
    "    # Run the training inside a session.\n",
    "    final_loss = slim.learning.train(\n",
    "        train_op,\n",
    "        logdir=ckpt_dir,\n",
    "        number_of_steps=5000,\n",
    "        save_summaries_secs=5,\n",
    "        log_every_n_steps=500)\n",
    "\n",
    "print(\"Finished training. Last batch loss:\", final_loss)\n",
    "print(\"Checkpoint saved in %s\" % ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:42:56.919850Z",
     "start_time": "2019-05-16T01:42:50.392828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/regression_model/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path tmp/regression_model/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global step 5500: loss = 0.1891 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 6000: loss = 0.1878 (0.001 sec/step)\n",
      "INFO:tensorflow:global step 6500: loss = 0.1813 (0.001 sec/step)\n",
      "INFO:tensorflow:global step 7000: loss = 0.1681 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 7500: loss = 0.2076 (0.001 sec/step)\n",
      "INFO:tensorflow:global step 8000: loss = 0.1823 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 8500: loss = 0.1778 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 9000: loss = 0.1805 (0.001 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 860.889\n",
      "INFO:tensorflow:global step 9500: loss = 0.1765 (0.000 sec/step)\n",
      "INFO:tensorflow:global step 10000: loss = 0.1644 (0.000 sec/step)\n",
      "INFO:tensorflow:Stopping Training.\n",
      "INFO:tensorflow:Finished training! Saving model to disk.\n",
      "Finished training. Last batch loss: 0.16444096\n",
      "Checkpoint saved in tmp/regression_model/\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    inputs, targets = convert_data_to_tensors(x_train, y_train)\n",
    "\n",
    "    # Make the model.\n",
    "    predictions, nodes = regression_model(inputs, is_training=True)\n",
    "\n",
    "    # Add the loss function to the graph.\n",
    "    loss = tf.losses.mean_squared_error(labels=targets, predictions=predictions)\n",
    "    \n",
    "    # The total loss is the user's loss plus any regularization losses.\n",
    "    total_loss =  tf.losses.get_total_loss()# slim.losses.get_total_loss()\n",
    "\n",
    "    # Specify the optimizer and create the train op:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)\n",
    "    train_op = slim.learning.create_train_op(total_loss, optimizer) \n",
    "\n",
    "    # Run the training inside a session.\n",
    "    final_loss = slim.learning.train(\n",
    "        train_op,\n",
    "        logdir=ckpt_dir,\n",
    "        number_of_steps=5000 + 5000,\n",
    "        save_summaries_secs=5,\n",
    "        log_every_n_steps=500)\n",
    "\n",
    "print(\"Finished training. Last batch loss:\", final_loss)\n",
    "print(\"Checkpoint saved in %s\" % ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T02:52:04.044159Z",
     "start_time": "2019-05-15T02:52:03.912301Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls tmp/regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using slim to define layers and for loop for trainning\n",
    "\n",
    "Google authors of vggish modesl did that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:22:07.719614Z",
     "start_time": "2019-05-16T01:22:07.592625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f4054053c18>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train = produce_batch(200)\n",
    "x_test, y_test = produce_batch(200)\n",
    "plt.scatter(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:22:11.134807Z",
     "start_time": "2019-05-16T01:22:11.131444Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_examples_batch():\n",
    "    \n",
    "    chosen_id = np.random.randint(0,200, 200)\n",
    "  \n",
    "    return x_train[chosen_id], y_train[chosen_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T18:28:48.837690Z",
     "start_time": "2019-05-16T18:27:55.530254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000 loss: 13.890503883361816\n",
      "Epoch 501/20000 loss: 0.6354789137840271\n",
      "Epoch 1001/20000 loss: 0.532836377620697\n",
      "Epoch 1501/20000 loss: 0.34529194235801697\n",
      "Epoch 2001/20000 loss: 0.3111180365085602\n",
      "Epoch 2501/20000 loss: 0.31446412205696106\n",
      "Epoch 3001/20000 loss: 0.281959593296051\n",
      "Epoch 3501/20000 loss: 0.27950334548950195\n",
      "Epoch 4001/20000 loss: 0.26129385828971863\n",
      "Epoch 4501/20000 loss: 0.20744262635707855\n",
      "Epoch 5001/20000 loss: 0.26515287160873413\n",
      "Epoch 5501/20000 loss: 0.28346091508865356\n",
      "Epoch 6001/20000 loss: 0.25347667932510376\n",
      "Epoch 6501/20000 loss: 0.3083786070346832\n",
      "Epoch 7001/20000 loss: 0.25521084666252136\n",
      "Epoch 7501/20000 loss: 0.2521083950996399\n",
      "Epoch 8001/20000 loss: 0.22878853976726532\n",
      "Epoch 8501/20000 loss: 0.25378623604774475\n",
      "Epoch 9001/20000 loss: 0.24805095791816711\n",
      "Epoch 9501/20000 loss: 0.1485598385334015\n",
      "Epoch 10001/20000 loss: 0.26677417755126953\n",
      "Epoch 10501/20000 loss: 0.20699471235275269\n",
      "Epoch 11001/20000 loss: 0.21381133794784546\n",
      "Epoch 11501/20000 loss: 0.24422800540924072\n",
      "Epoch 12001/20000 loss: 0.2318820208311081\n",
      "Epoch 12501/20000 loss: 0.17780053615570068\n",
      "Epoch 13001/20000 loss: 0.16490447521209717\n",
      "Epoch 13501/20000 loss: 0.23209592700004578\n",
      "Epoch 14001/20000 loss: 0.22332382202148438\n",
      "Epoch 14501/20000 loss: 0.24010713398456573\n",
      "Epoch 15001/20000 loss: 0.14105254411697388\n",
      "Epoch 15501/20000 loss: 0.1909298449754715\n",
      "Epoch 16001/20000 loss: 0.22577741742134094\n",
      "Epoch 16501/20000 loss: 0.26769402623176575\n",
      "Epoch 17001/20000 loss: 0.18101459741592407\n",
      "Epoch 17501/20000 loss: 0.15785470604896545\n",
      "Epoch 18001/20000 loss: 0.1644301563501358\n",
      "Epoch 18501/20000 loss: 0.2224082499742508\n",
      "Epoch 19001/20000 loss: 0.1635947823524475\n",
      "Epoch 19501/20000 loss: 0.1796310842037201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3ffa3a4c18>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt_dir = 'tmp/regression_model2/'\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    with tf.variable_scope('mymodel'):\n",
    "    \n",
    "        #inputs, targets = convert_data_to_tensors(x_train, y_train)\n",
    "        inputs = tf.placeholder(tf.float32, shape=(None, 1), name='inputs')\n",
    "        targets = tf.placeholder(tf.float32, shape=(None, 1), name='targets')\n",
    "        \n",
    "        # Make the model.\n",
    "        predictions, nodes = regression_model(inputs, is_training=True)\n",
    "\n",
    "        with tf.variable_scope('train'):\n",
    "            \n",
    "            # You need this to save the model\n",
    "            global_step = tf.Variable(0, name='global_step', \n",
    "                                      trainable=False,\n",
    "                                    collections=[tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                     tf.GraphKeys.GLOBAL_STEP])\n",
    "            \n",
    "            # Add the loss function to the graph.\n",
    "            loss = tf.losses.mean_squared_error(labels=targets, predictions=predictions)\n",
    "    \n",
    "            # The total loss is the user's loss plus any regularization losses.\n",
    "            total_loss =  tf.losses.get_total_loss()# slim.losses.get_total_loss()\n",
    "            \n",
    "            # Specify the optimizer and create the train op:\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)    \n",
    "            optimizer.minimize(total_loss,global_step=global_step, name='train_op')\n",
    "            \n",
    "            train_op = sess.graph.get_operation_by_name('mymodel/train/train_op')\n",
    "            \n",
    "            targets_tensor = sess.graph.get_tensor_by_name('mymodel/targets:0')\n",
    "            inputs_tensor = sess.graph.get_tensor_by_name('mymodel/inputs:0')\n",
    "            global_step_tensor = sess.graph.get_tensor_by_name('mymodel/train/global_step:0')\n",
    "\n",
    "    # Initialize all variables in the model, and then load the pre-trained\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    minibatch_size = 50\n",
    "    n_batches = 20000\n",
    "    costs= []\n",
    "    for _num_batches in range(n_batches):\n",
    "                    \n",
    "        # Dynamic creates systehetic data\n",
    "        (xt, yt) = _get_examples_batch()\n",
    "        \n",
    "        for i in range(0, 200, minibatch_size):\n",
    "        \n",
    "            # Get pair of (X, y) of the current minibatch/chunk\n",
    "            x_mini = xt[i:i + minibatch_size]\n",
    "            y_mini = yt[i:i + minibatch_size]\n",
    "\n",
    "            [loss, num_steps, _] = sess.run( [ total_loss, train_op, global_step_tensor],\n",
    "                                  feed_dict={inputs_tensor: x_mini, targets_tensor: y_mini })\n",
    "        \n",
    "        if _num_batches % 500 == 0:\n",
    "            costs.append(loss)\n",
    "            print(\"Epoch {}/{} loss: {}\".format(_num_batches + 1,n_batches, loss ))\n",
    "    \n",
    "    \n",
    "    # Prediction\n",
    "    #inputs, targets = convert_data_to_tensors(x_test, y_test)\n",
    "  \n",
    "    # Create the model structure. (Parameters will be loaded below.)\n",
    "    predictions, end_points = regression_model(inputs, is_training=False)\n",
    "\n",
    "#     # Make a session which restores the old parameters from a checkpoint.\n",
    "#     inputs, predictions, targets = sess.run([inputs, predictions, targets],\n",
    "#                                            feed_dict={inputs_tensor: x_test, targets_tensor: y_test })\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "plt.plot(costs, c='b')\n",
    "plt.plot(np.ones(len(costs))*0.12,c='r')\n",
    "\n",
    "# plt.scatter(inputs, targets, c='r');\n",
    "# plt.scatter(inputs, predictions, c='b');\n",
    "# plt.title('red=true, blue=predicted')\n",
    "    \n",
    "#     # Save model to disk.\n",
    "#     saver = tf.train.Saver()\n",
    "#     save_path = saver.save(sess,ckpt_dir, global_step = _num_batches)\n",
    "#     print(\"Model saved to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T02:03:23.517717Z",
     "start_time": "2019-05-16T02:03:23.303829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/regression_model2/-9999\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.NotFoundError'>, Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n",
      "\n",
      "Key deep_regression/fc1/biases not found in checkpoint\n",
      "\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
      "\n",
      "Caused by op 'save/RestoreV2', defined at:\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-607bc736f93d>\", line 10, in <module>\n",
      "    sv = tf.train.Supervisor(logdir=ckpt_dir)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 272, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 321, in __init__\n",
      "    self._init_saver(saver=saver)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 471, in _init_saver\n",
      "    saver = saver_mod.Saver()\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n",
      "    self.build()\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n",
      "    self._build(self._filename, build_save=True, build_restore=True)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n",
      "    build_save=build_save, build_restore=build_restore)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n",
      "    restore_sequentially, reshape)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 397, in _AddRestoreOps\n",
      "    restore_sequentially)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 829, in bulk_restore\n",
      "    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n",
      "    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "NotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n",
      "\n",
      "Key deep_regression/fc1/biases not found in checkpoint\n",
      "\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
      "\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey deep_regression/fc1/biases not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/leandroohf/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-607bc736f93d>\", line 10, in <module>\n    sv = tf.train.Supervisor(logdir=ckpt_dir)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 272, in new_func\n    return func(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 321, in __init__\n    self._init_saver(saver=saver)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 471, in _init_saver\n    saver = saver_mod.Saver()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 397, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 829, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey deep_regression/fc1/biases not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key deep_regression/fc1/biases not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1724\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1725\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1726\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key deep_regression/fc1/biases not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/leandroohf/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-607bc736f93d>\", line 10, in <module>\n    sv = tf.train.Supervisor(logdir=ckpt_dir)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 272, in new_func\n    return func(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 321, in __init__\n    self._init_saver(saver=saver)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 471, in _init_saver\n    saver = saver_mod.Saver()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 397, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 829, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key deep_regression/fc1/biases not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1736\u001b[0m         object_graph_string = reader.get_tensor(\n\u001b[0;32m-> 1737\u001b[0;31m             checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[1;32m   1738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    350\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[0;32m--> 351\u001b[0;31m                                           status)\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-607bc736f93d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Make a session which restores the old parameters from a checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupervisor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanaged_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\u001b[0m in \u001b[0;36mmanaged_session\u001b[0;34m(self, master, config, start_standard_services, close_summary_writer)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;31m# threads which are not checking for `should_stop()`.  They\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;31m# will be stopped when we close the session further down.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_summary_writer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose_summary_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;31m# Close the session to finish up all pending calls.  We do not care\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self, threads, close_summary_writer, ignore_live_threads)\u001b[0m\n\u001b[1;32m    831\u001b[0m           \u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m           \u001b[0mstop_grace_period_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_grace_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m           ignore_live_threads=ignore_live_threads)\n\u001b[0m\u001b[1;32m    834\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0;31m# Close the writer last, in case one of the running threads was using it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\u001b[0m in \u001b[0;36mmanaged_session\u001b[0;34m(self, master, config, start_standard_services, close_summary_writer)\u001b[0m\n\u001b[1;32m    992\u001b[0m       sess = self.prepare_or_wait_for_session(\n\u001b[1;32m    993\u001b[0m           \u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m           start_standard_services=start_standard_services)\n\u001b[0m\u001b[1;32m    995\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\u001b[0m in \u001b[0;36mprepare_or_wait_for_session\u001b[0;34m(self, master, config, wait_for_checkpoint, max_wait_secs, start_standard_services)\u001b[0m\n\u001b[1;32m    729\u001b[0m           \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m           \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m           init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\n\u001b[0m\u001b[1;32m    732\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstart_standard_services\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         config=config)\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Loads the checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover_last_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_model_checkpoint_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1743\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey deep_regression/fc1/biases not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/leandroohf/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-607bc736f93d>\", line 10, in <module>\n    sv = tf.train.Supervisor(logdir=ckpt_dir)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 272, in new_func\n    return func(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 321, in __init__\n    self._init_saver(saver=saver)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 471, in _init_saver\n    saver = saver_mod.Saver()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 397, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 829, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/leandroohf/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey deep_regression/fc1/biases not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "# do a prediction\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    inputs, targets = convert_data_to_tensors(x_test, y_test)\n",
    "  \n",
    "    # Create the model structure. (Parameters will be loaded below.)\n",
    "    predictions, end_points = regression_model(inputs, is_training=False)\n",
    "\n",
    "    # Make a session which restores the old parameters from a checkpoint.\n",
    "    sv = tf.train.Supervisor(logdir=ckpt_dir)\n",
    "    with sv.managed_session() as sess:\n",
    "        inputs, predictions, targets = sess.run([inputs, predictions, targets])\n",
    "\n",
    "plt.scatter(inputs, targets, c='r');\n",
    "plt.scatter(inputs, predictions, c='b');\n",
    "plt.title('red=true, blue=predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Evaluation model\n",
    "\n",
    "TODO: NOT working Is hard or complicated to work with\n",
    "\n",
    "You have to run the script in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:09:35.721474Z",
     "start_time": "2019-05-15T03:09:35.495326Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = 'tmp/log'\n",
    "\n",
    "# Choose the metrics to compute:\n",
    "names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\n",
    "    'RMSE Linear': slim.metrics.streaming_mean_squared_error(predictions=predictions, labels=targets),\n",
    "    'Mean Abs Error': slim.metrics.streaming_mean_absolute_error(predictions, targets)\n",
    "})\n",
    "\n",
    "\n",
    "# Create the summary ops such that they also print out to std output:\n",
    "summary_ops = []\n",
    "for metric_name, metric_value in names_to_values.items():\n",
    "     \n",
    "    op = tf.summary.scalar(metric_name, metric_value)\n",
    "    op = tf.Print(op, [metric_value], metric_name)\n",
    "    summary_ops.append(op)\n",
    "\n",
    "num_examples = 10000\n",
    "batch_size = 32\n",
    "num_batches = math.ceil(num_examples / float(batch_size))\n",
    "\n",
    "# Setup the global step.\n",
    "slim.get_or_create_global_step()\n",
    "\n",
    "output_dir = 'tmp/regression_model/' # Where the summaries are stored.\n",
    "eval_interval_secs = 0.5 # How often to run the evaluation.\n",
    "\n",
    "slim.evaluation.evaluation_loop(\n",
    "    'local',\n",
    "    ckpt_dir,\n",
    "    log_dir,\n",
    "    num_evals=num_batches,\n",
    "    eval_op=names_to_updates.values(),\n",
    "    summary_op=tf.summary.merge(summary_ops),\n",
    "    eval_interval_secs=eval_interval_secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Convolutional (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:22:57.512166Z",
     "start_time": "2019-05-15T03:22:57.488726Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datasets import flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T04:00:02.672036Z",
     "start_time": "2019-05-15T04:00:02.666604Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def my_cnn(images, num_classes, is_training):  # is_training is not used...\n",
    "    \n",
    "    with slim.arg_scope([slim.max_pool2d], kernel_size=[3, 3], stride=2):\n",
    "        net = slim.conv2d(images, 64, [5, 5])\n",
    "        net = slim.max_pool2d(net)\n",
    "        net = slim.conv2d(net, 64, [5, 5])\n",
    "        net = slim.max_pool2d(net)\n",
    "        net = slim.flatten(net)\n",
    "        net = slim.fully_connected(net, 192)\n",
    "        net = slim.fully_connected(net, num_classes, activation_fn=None)       \n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T04:01:28.182830Z",
     "start_time": "2019-05-15T04:01:28.177477Z"
    },
    "hidden": true
   },
   "source": [
    "**Apply the model to some randomly generated images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T04:00:44.860880Z",
     "start_time": "2019-05-15T04:00:44.670398Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # The model can handle any input size because the first layer is convolutional.\n",
    "    # The size of the model is determined when image_node is first passed into the my_cnn function.\n",
    "    # Once the variables are initialized, the size of all the weight matrices is fixed.\n",
    "    # Because of the fully connected layers, this means that all subsequent images must have the same\n",
    "    # input size as the first image.\n",
    "    batch_size, height, width, channels = 3, 28, 28, 3\n",
    "    images = tf.random_uniform([batch_size, height, width, channels], maxval=1)\n",
    "    \n",
    "    # Create the model.\n",
    "    num_classes = 10\n",
    "    logits = my_cnn(images, num_classes, is_training=True)\n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "  \n",
    "    # Initialize all the variables (including parameters) randomly.\n",
    "    init_op = tf.global_variables_initializer()\n",
    "  \n",
    "    with tf.Session() as sess:\n",
    "        # Run the init_op, evaluate the model outputs and print the results:\n",
    "        sess.run(init_op)\n",
    "        probabilities = sess.run(probabilities)\n",
    "        \n",
    "print('Probabilities Shape:')\n",
    "print(probabilities.shape)  # batch_size x num_classes \n",
    "\n",
    "print('\\nProbabilities:')\n",
    "print(probabilities)\n",
    "\n",
    "print('\\nSumming across all classes (Should equal 1):')\n",
    "print(np.sum(probabilities, 1)) # Each row sums to 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
